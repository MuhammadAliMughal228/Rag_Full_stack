# Conversational RAG with PDF Uploads and Chat History

## ğŸ“Œ Overview
This project is a **Conversational Retrieval-Augmented Generation (RAG) chatbot** that allows users to:
- **Upload PDF documents** and extract their content into a vector database.
- **Ask questions** about the uploaded PDFs using AI-powered retrieval and response generation.
- **Store chat history** for maintaining conversational context.

The system is built using **FastAPI (backend)**, **Streamlit (frontend)**, **Pinecone (vector storage)**, and **OpenAI embeddings & LLMs**.

---

## ğŸ—ï¸ Project Structure
```plaintext
ğŸ“‚ Conversational-RAG-Chatbot
â”‚â”€â”€ ğŸ“‚ backend          # FastAPI Backend (Handles AI interactions, vector storage, PDF processing)
â”‚   â”œâ”€â”€ app
â”‚   â”‚   â”œâ”€â”€ main.py      # Main FastAPI application
â”‚   â”‚   â”œâ”€â”€ settings.py  # API keys and configurations
â”‚   â”‚   â”œâ”€â”€ models.py    # Data models (chat history, queries)
â”‚   â”‚   â”œâ”€â”€ utils.py     # Helper functions for processing data
â”‚â”€â”€ ğŸ“‚ frontend         # Streamlit UI (User interaction)
â”‚   â”œâ”€â”€ app.py          # Main Streamlit application
â”‚â”€â”€ ğŸ“‚ data             # Stores uploaded PDFs (temporary storage)
â”‚â”€â”€ ğŸ“‚ docker           # Docker setup files
â”‚â”€â”€ .env               # Environment variables (API Keys, Database info)
â”‚â”€â”€ docker-compose.yml  # Docker Compose configuration
â”‚â”€â”€ README.md           # This guide
```

---

## ğŸ”§ Prerequisites
Before you begin, make sure you have the following installed:

- **Docker & Docker Compose**
- **Python 3.9+** (If running outside Docker)
- **Pinecone, OpenAI, Groq API Keys**
- **Poetry** (For dependency management)

---

## ğŸš€ Setup & Installation
### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/ahadnaeem785/Conversational-RAG-Chatbot.git
cd Conversational-RAG-Chatbot
```

### **2ï¸âƒ£ Set Up Environment Variables**
Create a **`.env`** file in the root directory and add:
```plaintext
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENV=your_pinecone_environment
GROQ_API_KEY=your_groq_api_key
```

### **3ï¸âƒ£ Run the Application (Using Docker)**
```sh
docker-compose up --build
```
This will:
- Start **FastAPI (Backend) on port `8000`**
- Start **Streamlit UI (Frontend) on port `8501`**

**Access the UI:** `http://localhost:8501`
**API Docs:** `http://localhost:8000/docs`


---

## ğŸ“Œ Usage Guide
### **ğŸ”¹ Upload a PDF**
1. Open `http://localhost:8501`
2. Click **"Choose a PDF File"** and upload a document.
3. Once uploaded, the document content is processed and stored in Pinecone.

### **ğŸ”¹ Ask Questions About the PDF**
1. Enter your **Session ID** (default: `default_session`).
2. Type a **question related to the uploaded PDF**.
3. The chatbot will retrieve relevant information and respond based on the document content.
4. Chat history will be displayed on the UI.

### **ğŸ”¹ API Endpoints (For Developers)**
| Method | Endpoint          | Description |
|--------|-----------------|-------------|
| `POST` | `/upload-pdf/`   | Uploads and processes a PDF file |
| `POST` | `/ask/`          | Asks a question about the uploaded PDF |
| `GET`  | `/docs`          | Access API documentation |


---

## ğŸ¯ Troubleshooting
### ğŸ”¹ **Backend Not Starting?**
- Ensure `.env` file is correctly configured.
- Run `docker-compose logs backend` to check logs.

### ğŸ”¹ **Frontend Not Working?**
- Ensure the backend is running before starting Streamlit.
- Run `docker-compose logs frontend` to check logs.

### ğŸ”¹ **API Not Responding?**
- Run a manual test: `curl -X POST "http://localhost:8000/ask/" -H "Content-Type: application/json" -d '{"session_id": "default", "question": "What is AI?"}'`

---

## ğŸ“Œ Future Improvements
- âœ… Support for multiple PDFs
- âœ… UI enhancements for better user experience
- âœ… Deploy on cloud (AWS/GCP/Azure)

---
.

ğŸš€ **Happy Coding!**

